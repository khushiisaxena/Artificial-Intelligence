{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHG9CKs+p6owzmCYIBj9wq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushiisaxena/Artificial-Intelligence/blob/main/AI_Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 1\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "book = 'war_and_peace.txt'\n",
        "file = open(book, 'r', encoding='utf-8')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "# Removing the punctuations and converting to lower case\n",
        "text = re.sub(r'[^a-zA-Z]', \" \", text)\n",
        "text = \" \".join(text.split()).lower()[:100000]\n",
        "\n",
        "# Creating a dictionary of all the unique characters\n",
        "dictionary = {}\n",
        "for i in range(26):\n",
        "    dictionary[chr(i + 97)] = i\n",
        "dictionary[\" \"] = 26\n",
        "\n",
        "# Initialize the parameters\n",
        "O = np.zeros(len(text), dtype=int)\n",
        "for i in range(len(text)):\n",
        "    O[i] = dictionary[text[i]]\n",
        "\n",
        "# Initial state distribution\n",
        "pi = np.array(([0.525483, 0.474517]))\n",
        "\n",
        "# Observable sequence\n",
        "B = np.array([[0.03735, 0.03408, 0.03455, 0.03828, 0.03782, 0.03922, 0.03688, 0.03408, 0.03875, 0.04062, 0.03735, 0.03968, 0.03548, 0.03735, 0.04062, 0.03595, 0.03641, 0.03408, 0.04062, 0.03548, 0.03922, 0.04062, 0.03455, 0.03595, 0.03408, 0.03408, 0.03688],\n",
        "              [0.03909, 0.03537, 0.03537, 0.03909, 0.03583, 0.03630, 0.04048, 0.03537, 0.03816, 0.03909, 0.03490, 0.03723, 0.03537, 0.03909, 0.03397, 0.03397, 0.03816, 0.03676, 0.04048, 0.03443, 0.03537, 0.03955, 0.03816, 0.03723, 0.03769, 0.03955, 0.03397]])\n",
        "\n",
        "# Transition matrix\n",
        "A = np.array([[0.47468, 0.52532], [0.51656, 0.48344]])\n",
        "\n",
        "# Set of possible observations\n",
        "V = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' '])\n",
        "\n",
        "# Set of possible states, Q is hidden\n",
        "# Number of observation symbols\n",
        "M = len(V)\n",
        "\n",
        "# Number of states in the model\n",
        "N = len(A)\n",
        "\n",
        "# Length of observation sequence\n",
        "T = len(O)  # Defined after O\n",
        "\n",
        "# Alpha Pass\n",
        "def alpha_pass(A1, B1, pi1, O1):\n",
        "    c1 = np.zeros([T, 1])\n",
        "    alpha1 = np.zeros([T, N])\n",
        "    c1[0][0] = 0\n",
        "    for x in range(N):\n",
        "        alpha1[0][x] = pi1[x] * B1[x][O1[0]]\n",
        "        c1[0][0] = c1[0][0] + alpha1[0][x]\n",
        "    c1[0][0] = 1/c1[0][0]\n",
        "    for x in range(N):\n",
        "        alpha1[0][x] = c1[0][0] * alpha1[0][x]\n",
        "    for t in range(1, T):\n",
        "        c1[t][0] = 0\n",
        "        for x in range(N):\n",
        "            alpha1[t][x] = 0\n",
        "            for y in range(N):\n",
        "                alpha1[t][x] = alpha1[t][x] + alpha1[t-1][y] * A1[y][x]\n",
        "            alpha1[t][x] = alpha1[t][x] * B1[x][O1[t]]\n",
        "            c1[t][0] = c1[t][0] + alpha1[t][x]\n",
        "        c1[t][0] = 1/c1[t][0]\n",
        "        for x in range(N):\n",
        "            alpha1[t][x] = c1[t][0] * alpha1[t][x]\n",
        "    return alpha1, c1\n",
        "\n",
        "# Beta Pass\n",
        "def beta_pass(A1, B1, O1, c1):\n",
        "    beta1 = np.zeros([T, N])\n",
        "    for x in range(N):\n",
        "        beta1[T-1][x] = c1[T-1][0]\n",
        "    for t in range(T-2, -1, -1):\n",
        "        for x in range(N):\n",
        "            beta1[t][x] = 0\n",
        "            for y in range(N):\n",
        "                beta1[t][x] = beta1[t][x] + A1[x][y] * B1[y][O1[t + 1]] * beta1[t + 1][y]\n",
        "            beta1[t][x] = c1[t][0] * beta1[t][x]\n",
        "    return beta1\n",
        "\n",
        "# Compute Gamma(x,t) and Gamma(x,y,t)\n",
        "def gamma_pass(alpha1, beta1, A1, B1, O1):\n",
        "    gamma1 = np.zeros([T, N])\n",
        "    di_gamma1 = np.zeros([T, N, N])\n",
        "    for t in range(T-1):\n",
        "        for x in range(N):\n",
        "            gamma1[t][x] = 0\n",
        "            for y in range(N):\n",
        "                di_gamma1[t][x][y] = alpha1[t][x] * A1[x][y] * B1[y][O1[t + 1]] * beta1[t + 1][y]\n",
        "                gamma1[t][x] = gamma1[t][x] + di_gamma1[t][x][y]\n",
        "    for x in range(N):\n",
        "        gamma1[T-1][x] = alpha1[T-1][x]\n",
        "    return gamma1, di_gamma1\n",
        "\n",
        "# Re-estimate A, B, pi\n",
        "def re_estimate(gamma1, di_gamma1, A1, B1, pi1):\n",
        "    for x in range(N):\n",
        "        pi1[x] = gamma1[0][x]\n",
        "    for x in range(N):\n",
        "        denominator = 0\n",
        "        for t in range(T-1):\n",
        "            denominator = denominator + gamma1[t][x]\n",
        "        for y in range(N):\n",
        "            numerator = 0\n",
        "            for t in range(T-1):\n",
        "                numerator = numerator + di_gamma1[t][x][y]\n",
        "            A1[x][y] = numerator/denominator\n",
        "    for x in range(N):\n",
        "        denominator = 0\n",
        "        for t in range(T):\n",
        "            denominator = denominator + gamma1[t][x]\n",
        "        for y in range(M):\n",
        "            numerator = 0\n",
        "            for t in range(T):\n",
        "                if O[t] == y:\n",
        "                    numerator = numerator + gamma1[t][x]\n",
        "            B1[x][y] = numerator/denominator\n",
        "    return A1, B1, pi1\n",
        "\n",
        "# Compute log[P(O|lambda)]\n",
        "def log_prob(c1):\n",
        "    logProb1 = 0\n",
        "    for x in range(T):\n",
        "        logProb1 = logProb1 + np.log(c1[x][0])\n",
        "    logProb1 = -logProb1\n",
        "    return logProb1\n",
        "\n",
        "# Values initially\n",
        "oldLogProb = -10000000\n",
        "print(\"A: \\n\", A)\n",
        "print(\"B: \\n\", np.concatenate((V.reshape(1, M), B), axis=0).T)\n",
        "print(\"pi: \", pi)\n",
        "print(\"logProb: \", oldLogProb)\n",
        "\n",
        "# After first iteration\n",
        "alpha, c = alpha_pass(A, B, pi, O)\n",
        "beta = beta_pass(A, B, O, c)\n",
        "gamma, di_gamma = gamma_pass(alpha, beta, A, B, O)\n",
        "A, B, pi = re_estimate(gamma, di_gamma, A, B, pi)\n",
        "logProb = log_prob(c)\n",
        "print(\"A: \\n\", A)\n",
        "print(\"B: \\n\", np.concatenate((V.reshape(1, M), np.round_(B, decimals=7)), axis=0).T)\n",
        "print(\"pi: \", np.round_(pi, decimals=7))\n",
        "print(\"logProb: \", logProb)\n",
        "\n",
        "# After 100 iterations\n",
        "maxIter = 100\n",
        "for ite in range(maxIter):\n",
        "    alpha, c = alpha_pass(A, B, pi, O)\n",
        "    beta = beta_pass(A, B, O, c)\n",
        "    gamma, di_gamma = gamma_pass(alpha, beta, A, B, O)\n",
        "    A, B, pi = re_estimate(gamma, di_gamma, A, B, pi)\n",
        "    logProb = log_prob(c)\n",
        "    print(\"A: \\n\", A)\n",
        "    print(\"B: \\n\", np.concatenate((V.reshape(1, M), np.round_(B, decimals=7)), axis=0).T)\n",
        "    print(\"pi: \", np.round_(pi, decimals=5))\n",
        "    print(\"logProb: \", logProb)\n"
      ],
      "metadata": {
        "id": "DcvaCkC_dg0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 2\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.special import comb\n",
        "\n",
        "# Read the data from the CSV file\n",
        "df = pd.read_csv('/content/2020_ten_bent_coins.csv').transpose()\n",
        "\n",
        "# O being tail and 1 being head\n",
        "# counting number of heads and tails\n",
        "np.random.seed(0)\n",
        "heads = df.sum().to_numpy() # numpy array\n",
        "tails = 100 - heads\n",
        "selected_coin = np.random.randint(0,10,size=(500,)) # creating an array of 500 values with each one having value ranging from 1 to 10\n",
        "_, count_selected_coin = np.unique(selected_coin, return_counts=True) # count of which coin has been selected how many times\n",
        "\n",
        "# Maximum likelihood estimation\n",
        "MLE_vector = np.zeros(10)\n",
        "\n",
        "for i, j in zip(heads, selected_coin):\n",
        "    MLE_vector[j] += i\n",
        "\n",
        "# The MLE vector is then divided by the product of the count of the selected coin and the total number of tosses (100) to obtain the MLE estimates of the unknown bias values.\n",
        "MLE_vector = MLE_vector / (count_selected_coin * 100)\n",
        "\n",
        "# Function to compute likelihood\n",
        "def compute_likelihood(obs, n, pheads):\n",
        "    likelihood = comb(n, obs, exact=True) * (pheads ** obs) * ((1.0 - pheads) ** (n - obs))\n",
        "    return likelihood\n",
        "\n",
        "# Expectation-Maximization (EM) algorithm\n",
        "np.random.seed(0)\n",
        "p_heads = np.zeros((100, 10))\n",
        "p_heads[0] = np.random.random((1, 10))\n",
        "\n",
        "# The loop continues until the improvement in the MLE estimates between two consecutive iterations is less than a threshold eps, which is set to 0.01.\n",
        "eps = 0.01\n",
        "improvement = float('inf') # positive infinity\n",
        "epoch = 0\n",
        "\n",
        "while improvement > eps:\n",
        "    expectation = np.zeros((10, 500, 2))\n",
        "\n",
        "    for i in range(500):\n",
        "        e_head = heads[i]\n",
        "        e_tail = tails[i]\n",
        "        likelihood = np.zeros(10)\n",
        "\n",
        "        for j in range(10):\n",
        "            likelihood[j] = compute_likelihood(e_head, 100, p_heads[epoch][j])\n",
        "\n",
        "        weights = likelihood / np.sum(likelihood)\n",
        "\n",
        "        for j in range(10):\n",
        "            expectation[j][i] = weights[j] * np.array([e_head, e_tail])\n",
        "\n",
        "    theta = np.zeros(10)\n",
        "\n",
        "    for i in range(10):\n",
        "        theta[i] = np.sum(expectation[i], axis=0)[0] / np.sum(expectation[i])\n",
        "\n",
        "    p_heads[epoch + 1] = theta\n",
        "\n",
        "    print(f'Epoch ->{epoch}\\n Theta ->{theta}')\n",
        "\n",
        "    improvement = max(abs(p_heads[epoch + 1] - p_heads[epoch]))\n",
        "    epoch += 1\n",
        "\n",
        "# The MLE estimates are stored in the theta variable, which is the final output of the code.\n",
        "for i, j in enumerate(theta): # to get the index as well as value\n",
        "    print(f\"{i + 1} : {j:.3f}\")\n"
      ],
      "metadata": {
        "id": "TnMaaShHp_J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUESTION 3\n",
        "\n",
        "\n",
        "import pandas as pd # data manipulation\n",
        "import numpy as np # numerical operations\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Reading the data from csv file\n",
        "df = pd.read_csv(\"2020_em_clustering.csv\", sep=',', header=None)\n",
        "df = df.transpose()\n",
        "\n",
        "# Defining the number of clusters\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "\n",
        "# We use the train model to predict the cluster labels for each data point\n",
        "kmeans.fit(df)\n",
        "predictions = kmeans.predict(df)\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.scatter(df.iloc[:,0], [i for i in range(df.shape[0])], c=predictions)\n",
        "plt.xlabel(\"position\")\n",
        "plt.ylabel(\"Classification\")\n",
        "plt.show()\n",
        "\n",
        "# Reading the data from csv file\n",
        "df2 = pd.read_csv(\"2020_em_clustering.csv\", sep=',', header=None)\n",
        "df2 = df2.transpose()\n",
        "\n",
        "# Defining the number of clusters\n",
        "em = GaussianMixture(n_components=2)\n",
        "\n",
        "# Fitting the model\n",
        "em.fit(df2)\n",
        "\n",
        "# Predicting the clusters\n",
        "predictions = em.predict(df2)\n",
        "\n",
        "# Plotting the clusters\n",
        "plt.scatter(df2.iloc[:,0], [i for i in range(df2.shape[0])], c=predictions)\n",
        "plt.xlabel(\"position\")\n",
        "plt.ylabel(\"Classification\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XBZ2qHZLd82C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
